[
["index.html", "XAI Stories Preface", " XAI Stories 2020-04-03 Preface This book is the result of a student projects for Interpretable Machine Learning course at the University of Warsaw and the Warsaw University of Technology. Each team has prepared one case study for selected XAI technique. This project is inspired by a fantastic book Limitations of Interpretable Machine Learning Methods created at the Department of Statistics, LMU Munich. We used the LIML project as the cornerstone for this repository. The book chapters are written in the Markdown language. The simulations, data examples and visualizations were created with R (R Core Team 2018) and Python. The book was compiled with the bookdown package. We collaborated using github repository. Cover by kozaka93. Creative Commons License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],
["foreword.html", "Foreword 0.1 Why? 0.2 What? 0.3 How?", " Foreword Author: Przemyslaw Biecek (Warsaw University of Technology and University of Warsaw) 0.1 Why? Machine learning has a number of applications. Very often, however, machine learning predictive models are treated as black boxes which can be automatically trained without worrying about the domain in which they are used. This opaqueness rises many risks that are difficult to foresee during the model building process. Such as the model’s declining performance due to the data drift, poor performance on the out-of-domain problems or unfair biased behaviour learned on historical data. The growing list of examples where black boxes fail spectacularly has led to an increased interest in XAI methods. Such methods allow to x-ray black boxes models for more detailed analysis on the local or global level. According to Gartner Hype Cycle for Emerging Technologies in 2019 Explainable AI is on the verge of Innovation trigger and Peak of inflated expectations. It is a technology with a very high potential, which is talked about a lot in the media and which heats up the imagination as strongly as AI. In the literature there are many articles arguing the need to use XAI methods as well as many ideas for new methods from the XAI family. However, it is much more difficult to find examples of successful implementations of XAI methods that have improved the business. Missing elements are case studies of actual use of XAI methods in machine learning problems. Such case studies would allow a better understanding of what is possible today and what is not possible using XAI methods. 0.2 What? This ebook collects examples of the use of different methods from the XAI family for different real-world predictive problems. In the following chapters, we show example applications of different XAI techniques to problems based on real-world public dataset. These examples are called XAI stories and like every good story, each one has a structure. It starts with a description of the predictive problem, goes on to describe the proposed model or models. The models are x-rays using XAI techniques to finish the chapter with a point. 0.3 How? For XAI stories to be credible they need not only a strong predictive model, but also business validation of the proposed modeling and explanation approach. Each group of students got two mentors from McKinsey’s Data Science department. The mentors, together with the students, searched for strengths and weaknesses of XAI applications in specific problems. TODO: write more about this collaboration "],
["story-covid19.html", "1 Story covid19: eXplainable predictions for mortality 1.1 Introduction 1.2 Model 1.3 Explanations 1.4 Summary and conclusions", " 1 Story covid19: eXplainable predictions for mortality Authors: Author 1 (University 1), Author 2 (University 2), Author 3 (University 3) Mentors: Mentor 1 (Affiliation 1), Mentor 2 (Affiliation 2) 1.1 Introduction Put a description of the problem here. indicate the data source. Describe why this problem is important. Indicate the most important literature on the problem. 1.2 Model Place a description of the model(s) here. Focus on key information on the design and quality of the model(s) developed. 1.3 Explanations Here, show how XAI techniques can be used to solve the problem. Will dataset specific or instance specific techniques help more? Will XAI be useful before (pre), during (in) or after (post) modeling? What is interesting to learn from the XAI analysis? 1.4 Summary and conclusions Here add the most important conclusions related to the XAI analysis. What did you learn? Where were the biggest difficulties? What else did you recommend? "],
["story-lungs.html", "2 Story lungs: eXplainable predictions for post operational risks 2.1 Introduction 2.2 Model 2.3 Explanations 2.4 Summary and conclusions", " 2 Story lungs: eXplainable predictions for post operational risks Authors: Author 1 (University 1), Author 2 (University 2), Author 3 (University 3) Mentors: Mentor 1 (Affiliation 1), Mentor 2 (Affiliation 2) 2.1 Introduction Put a description of the problem here. indicate the data source. Describe why this problem is important. Indicate the most important literature on the problem. 2.2 Model Place a description of the model(s) here. Focus on key information on the design and quality of the model(s) developed. 2.3 Explanations Here, show how XAI techniques can be used to solve the problem. Will dataset specific or instance specific techniques help more? Will XAI be useful before (pre), during (in) or after (post) modeling? What is interesting to learn from the XAI analysis? 2.4 Summary and conclusions Here add the most important conclusions related to the XAI analysis. What did you learn? Where were the biggest difficulties? What else did you recommend? "],
["story-compas.html", "3 Story COMPAS: recidivism reloaded 3.1 Introduction 3.2 Model 3.3 Explanations 3.4 Summary and conclusions", " 3 Story COMPAS: recidivism reloaded Authors: Author 1 (University 1), Author 2 (University 2), Author 3 (University 3) Mentors: Mentor 1 (Affiliation 1), Mentor 2 (Affiliation 2) 3.1 Introduction Put a description of the problem here. indicate the data source. Describe why this problem is important. Indicate the most important literature on the problem. 3.2 Model Place a description of the model(s) here. Focus on key information on the design and quality of the model(s) developed. 3.3 Explanations Here, show how XAI techniques can be used to solve the problem. Will dataset specific or instance specific techniques help more? Will XAI be useful before (pre), during (in) or after (post) modeling? What is interesting to learn from the XAI analysis? 3.4 Summary and conclusions Here add the most important conclusions related to the XAI analysis. What did you learn? Where were the biggest difficulties? What else did you recommend? "],
["acknowledgements.html", "4 Acknowledgements", " 4 Acknowledgements This project is inspired by a fantastic book Limitations of Interpretable Machine Learning Methods created at the Department of Statistics, LMU Munich. We used the LIML project as cornerstone for this reopsitory. "],
["references.html", "References", " References R Core Team. 2018. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/. "]
]
